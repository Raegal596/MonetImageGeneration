{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30170,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# This notebook borrows heavily from:\n# https://www.kaggle.com/nachiket273/cyclegan-pytorch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-03T03:58:46.713118Z","iopub.execute_input":"2022-03-03T03:58:46.713914Z","iopub.status.idle":"2022-03-03T03:58:46.740817Z","shell.execute_reply.started":"2022-03-03T03:58:46.713812Z","shell.execute_reply":"2022-03-03T03:58:46.739912Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Import Dependencies\nLibraries for navigating the filesystem, for constructing the models, and for image processing.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nimport itertools\nimport matplotlib.pyplot as plt\nimport os\nimport PIL\nfrom PIL import Image\nimport random\nimport shutil\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_curve\nfrom sklearn import metrics\nimport time\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Initialize Device","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmonet_directory = '../input/gan-getting-started/monet_jpg/'\nphoto_directory = '../input/gan-getting-started/photo_jpg/'","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset and Data Loader","metadata":{}},{"cell_type":"code","source":"class MonetData(Dataset):\n    def __init__(self, monet_directory, photo_directory, \n                 transform = transforms.ToTensor()):\n        self.transform = transform\n        self.monet_paths = [os.path.join(monet_directory, p) for p in os.listdir(monet_directory)]\n        self.photo_paths = [os.path.join(photo_directory, p) for p in os.listdir(photo_directory)]\n    \n    # Return a monet paired with a random photo.\n    def __get_item__(self, idx):\n        monet = Image.open(monet_paths[idx])\n        monet = self.transform(monet)\n        \n        # Since the monet and photo directories contain a different number of images\n        # return a random photo from the directory\n        photo_idx = int(np.random.uniform(len(photo_paths)))\n        photo = Image.open(photo_paths[photo_idx])\n        photo = self.transform(photo)\n        \n        return monet, photo\n\n    # Return the minimum length of the list of files in the two directories.\n    def __len__(self):\n        return min(len(monet_paths), len(photo_paths))\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define the Models","metadata":{}},{"cell_type":"code","source":"class Conv_Wrapper():\n    __init__(self):\n        ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Generator():\n    __init__(self):","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Discriminator():\n    __init__(self):","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GAN():\n    def __init__(self):\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.monet_generator = Generator()\n        self.photo_generator = Generator()\n        self.monet_discriminator = Discriminator()\n        self.photo_discriminator = Discriminator()\n        \n        # Initialize weights for each of the networks.\n        \n        \n        # Send each of the models to GPU memory, if available.\n        self.monet_generator = self.monet_generator.to(self.device)\n        self.photo_generator = self.photo_generator.to(self.device)\n        self.monet_discriminator = self.monet_discriminator.to(self.device)\n        self.photo_discriminator = self.photo_discriminator.to(self.device)\n        \n        \n    def train(data_loader, epochs, lmbda = 10, identity_coefficient = 0.5):\n        generator_parameters = itertools.chain(self.monet_generator.parameters(),\n                                               self.photo_generator.parameters())\n        adam_generator = torch.optim.Adam(generator_parameters)\n        \n        discriminator_parameters = itertools.chain(self.monet_discriminator.parameters(),\n                                                   self.photo_discriminator.parameters())\n        adam_discriminator = torch.optim.Adam(discriminator_parameters)\n        \n        l1_loss = nn.L1Loss()\n        mse_loss = nn.MSELoss()\n        \n        for epoch in range(epochs):\n            for monet, photo in data_loader:\n                monet = monet.to(self.device)\n                photo = photo.to(self.device)\n                \n                adam_generator.zero_grad()\n                \n                # First call the generator to create a fake monet and \n                # a fake photo.\n                fake_monet = self.monet_generator(photo)\n                fake_photo = self.photo_generator(monet)\n                \n                # Pass the fakes back through to attempt to recover\n                # the originals.\n                cycle_monet = self.monet_generator(fake_photo)\n                cycle_photo = self.photo_generator(fake_monet)\n                \n                # Generate a monet and a photo from images that are\n                # already monets and photos. This should ideally\n                # leave the images relatively unaltered.\n                identity_monet = self.monet_generator(monet)\n                identity_photo = self.photo_generator(photo)\n                \n                # Run the fake monet and photo through the \n                # discriminator to see if it can differentiate the\n                # fakes.\n                for p in discriminator_parameters:\n                    p.requires_grad = False\n                monet_realism = self.monet_discriminator(fake_monet)\n                photo_realism = self.photo_discriminator(fake_photo)\n                \n                # Calculate the loss for the generator.\n                cycle_loss_monet = l1_loss(cycle_monet, monet) * lmbda\n                cycle_loss_photo = l1_loss(cycle_photo, photo) * lmbda\n                identity_loss_monet = l1_loss(identity_monet, monet) * lmbda * identity_coefficient\n                identity_loss_photo = l1_loss(identity_photo, photo) * lmbda * identity_coefficient\n                # TODO: review the dimensions for this.\n                real = 1\n                fake = 0\n                adverserial_loss_monet = mse_loss(monet_realism, real)\n                adverserial_loss_photo = mse_loss(photo_realism, real)\n                generator_loss = cycle_loss_monet + cycle_loss_photo\n                generator_loss += identity_loss_monet + identity_loss_photo\n                generator_loss += adverserial_loss_monet + adverserial_loss_photo\n                \n                # Update the parameters for the generator.\n                generator_loss.backward()\n                adam_generator.step()\n                \n                # Perform a forward step through the discriminator.\n                for p in discriminator_parameters:\n                    p.requires_grad = True\n                adam_discriminator.zero_grad()\n                \n                # TODO: check that the dimensions here are correct. The\n                # pass through the generator might result in additional\n                # parameters. If not, this process can be streamlined\n                # somewhat.\n                monet_discriminator_real = monet_discriminator(monet)\n                monet_discriminator_fake = monet_discriminator(fake_monet)\n                photo_discriminator_real = photo_discriminator(photo)\n                photo_discriminator_fake = photo_discriminator(fake_photo)\n                \n                # Calculate the loss for the discriminator.\n                real_loss_monet = mse_loss(monet_discriminator_real, real)\n                fake_loss_monet = mse_loss(monet_discriminator_fake, fake)\n                real_loss_monet = mse_loss(photo_discriminator_real, real)\n                fake_loss_monet = mse_loss(photo_discriminator_fake, fake)\n                discriminator_loss = real_loss_monet + fake_loss_monet\n                \n                discriminator_loss.backward()\n                adam_discriminator.step()\n                \n                \n                \n        gen_lr = lr_sched(self.decay_epoch, self.epochs)\n        desc_lr = lr_sched(self.decay_epoch, self.epochs)\n        self.gen_lr_sched = torch.optim.lr_scheduler.LambdaLR(self.adam_gen, gen_lr.step)\n        self.desc_lr_sched = torch.optim.lr_scheduler.LambdaLR(self.adam_desc, desc_lr.step)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}